{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workshop_MainFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Классификация и линейная регрессия со scikit-learn"
      ],
      "metadata": {
        "id": "Jf8hONl09_0n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt-6Ilw00Cbq"
      },
      "source": [
        "План:\n",
        "\n",
        "1. Наивная байесовская классификация.\n",
        "1. Алгоритм к-ближайших соседей."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 1. Наивная байесовская классификация документов"
      ],
      "metadata": {
        "id": "OlXtNJBI-S8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Описание метода"
      ],
      "metadata": {
        "id": "QbqC7c2oVEeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Описание метода представлено здесь:\n",
        "\n",
        "* РУС: [Наивный баейсовский классификатор](http://datascientist.one/naive-bayes/)\n",
        "* РУС: [6 простых шагов для освоения наивного байесовского алгоритма](http://datareview.info/article/6-prostyih-shagov-dlya-osvoeniya-naivnogo-bayesovskogo-algoritma-s-primerom-koda-na-python/)\n",
        "* ENG: [Naive Bayes Document Classification in Python](https://towardsdatascience.com/naive-bayes-document-classification-in-python-e33ff50f937e)\n",
        "* ENG: [A practical explanation of a Naive Bayes classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/)"
      ],
      "metadata": {
        "id": "kCZawLmH-f5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Выбор датасета"
      ],
      "metadata": {
        "id": "E9tPURpJ-em8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для самостоятельной работы предлагается выбрать один из датасетов\n",
        "\n",
        "* [Amazon Alexa Reviews](https://www.kaggle.com/sid321axn/amazon-alexa-reviews#amazon_alexa.tsv)\n",
        "\n",
        "* [Wine Reviews](https://www.kaggle.com/zynicide/wine-reviews)\n"
      ],
      "metadata": {
        "id": "j3ATikfAASYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном блокноте датасет взят [Women's E-Commerce Clothing Reviews](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews)."
      ],
      "metadata": {
        "id": "iKL_p1_4-31o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "GYvjHz7Q-d8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В ячейке ниже загружаем kaggle.json для вашей среды выполнения Colab, полученный на https://www.kaggle.com/.\n",
        "\n"
      ],
      "metadata": {
        "id": "HDs1uTQI_Dq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "s5Q6BIwM_EWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем папку, в которую выгрузим датасет:"
      ],
      "metadata": {
        "id": "FQdTOvyh_d3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/\n",
        "!mkdir reviews-dataset\n",
        "!cd /content/reviews-dataset"
      ],
      "metadata": {
        "id": "ASvuMMmS_e2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем датасет:"
      ],
      "metadata": {
        "id": "b8IUMdJi_1Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d nicapotato/womens-ecommerce-clothing-reviews -p /content/reviews-dataset"
      ],
      "metadata": {
        "id": "XjtNw8Z8_yUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx_68WPPcCen"
      },
      "source": [
        "### Получение DataFrame из датасета "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21kvIr7jz9HL"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 'Магическая' функция matplotlib\n",
        "%matplotlib inline \n",
        "\n",
        "# Есть пять предустановленная тем Seaborn: darkgrid, whitegrid, dark, white, \n",
        "# и ticks. Каждый из них подходит для различных приложений и личных предпочтений.\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CURENT_DIR = '/content/reviews-dataset'"
      ],
      "metadata": {
        "id": "IVyxEOeXADgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk9RPBtT0tKp"
      },
      "source": [
        "# Загрузить набор данных\n",
        "data = pd.read_csv(CURENT_DIR+'/womens-ecommerce-clothing-reviews.zip', sep=\",\")\n",
        "\n",
        "# Распечать первые 5 строк фрейма данных\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVr6UCIIck0P"
      },
      "source": [
        "### Выбор интересующих колонок"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Нас интересует текст, категория:"
      ],
      "metadata": {
        "id": "Gg7xFpZTCoDW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac4H_QZf01zc"
      },
      "source": [
        "df = data[['Review Text','Rating']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYw7RZYwcaWV"
      },
      "source": [
        "### Первичный осмотр выбранного датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0n8wG8L3fxb"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCmCVWyu3iQw"
      },
      "source": [
        "df['Review Text'] = df['Review Text'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxsxItsAdkxi"
      },
      "source": [
        "for col in df.columns:\n",
        "    print('{} - {}'.format(col, df[df[col].isnull()].shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEvD0Q9EdoR_"
      },
      "source": [
        "Датасет приведен в порядок, можно продолжать!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Разделение на тестовую и обучающую выборку"
      ],
      "metadata": {
        "id": "Lziufy6pDNr_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rqkZvOGdwKk"
      },
      "source": [
        "При построении предсказательных моделей исходные данные обычно разбиваются на обучающую (\"training set\") и контрольную (\"test set\", \"validation set\") выборки. Обучающая выборка используется собственно для \"обучения\" той или иной модели, т.е. для построения математических отношений между некоторой переменной-откликом и предикторами, тогда как контрольная (= \"проверочная\", \"экзаменационная\") выборка служит для получения оценки прогнозных свойств модели на новых данных, т.е. данных, которые не были использованы для обучения модели. Как правило, обучающая выборка составляет 75-80% от объема исходных данных, хотя каких-то строгих правил в этом отношении не существует. Рассмотрим, как можно выполнить подобное разбиение исходных данных на обучающую и контрольную выборки стандартными средствами R и при помощи пакета caret.\n",
        "\n",
        "Подробнее см. [здесь](https://r-analytics.blogspot.com/2015/08/blog-post_31.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9U7lMXn04h9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQVdsTMG1cdk"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['Review Text'], df['Rating'], random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzL0_RCM1zP9"
      },
      "source": [
        "print('X_train: {}  y_train: {}'.format(X_train.shape, y_train.shape))\n",
        "print('X_test: {}  y_test: {}'.format(X_test.shape, y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Работа с текстом"
      ],
      "metadata": {
        "id": "vcTyl2OYDcDi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnzE3GFLftiD"
      },
      "source": [
        "\n",
        "\n",
        "Наивный байесовский классификатор должен уметь вычислять, сколько раз каждое слово появляется в каждом документе и сколько раз оно появляется в каждой категории. Чтобы сделать это возможным, данные должны выглядеть примерно так:\n",
        "\n",
        "```\n",
        "[0, 1, 0, …]\n",
        "[1, 1, 1, …]\n",
        "[0, 2, 0, …]\n",
        "```\n",
        "\n",
        "Каждая строка представляет документ, а каждый столбец-слово.\n",
        "\n",
        "Одна из первых концепций обрабтки естественных языков [Bag-of-Words](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%88%D0%BE%D0%BA_%D1%81%D0%BB%D0%BE%D0%B2) — это статистический анализ, анализирующий количественное вхождение слов в документах. Не смотря на то, что подход сформирован весьма давно, он отлично подходит для первичной обработки текстов и быстрого прототипирования.\n",
        "\n",
        "Модуль [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) в `sklearn` как раз подзволяет сконвертировать набор текстов в матрицу токенов, находящихся в тексте. Также имеется много полезных настроек, например можно задать минимальное количество необходимое для появления токена в матрице и даже получить статистику по n-граммам. Следует учитывать, что `CountVectorizer` по умолчанию сам производит токенизацию и выкидывает слова с длиной меньшей чем два.\n",
        "\n",
        "См. подробнее [здесь](http://zabaykin.ru/?p=463)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пример работы CountVectorizer"
      ],
      "metadata": {
        "id": "Z_iFQ71KIk_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "     'This is the first document.',\n",
        "     'This document is the second document.',\n",
        "     'And this is the third one.',\n",
        "     'Is this the first document?',\n",
        "]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "THCLnsnVIrc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "sB2byNpwJsWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.toarray())"
      ],
      "metadata": {
        "id": "ZcpfmPLoJztC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
        "X2 = vectorizer2.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "RVZ2wYSHJ-4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer2.get_feature_names_out()"
      ],
      "metadata": {
        "id": "ZU1qza2MKAj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X2.toarray())"
      ],
      "metadata": {
        "id": "ZsRChLJeKWA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Применение CountVectorizer для датасета"
      ],
      "metadata": {
        "id": "B0tIXhnaKZ4n"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJs4INkp17P_"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(strip_accents='unicode', token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', lowercase=True, stop_words='english')\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cv.get_feature_names_out())"
      ],
      "metadata": {
        "id": "JRGqbTKUKe-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test_cv.toarray()[0])"
      ],
      "metadata": {
        "id": "krQAurjyKonx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIH2TbTlheT1"
      },
      "source": [
        "Мы можем использовать аргументы `strip_accents`, `token_pattern`, `lowercase` и `stopwords` для исключения \"стоп-слов\", чисел, артиклей и других вещей, которые не полезны для прогнозирования категорий из наших подсчетов. Дополнительные сведения см. в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB).\n",
        "\n",
        "Если вы хотите просмотреть данные и исследовать количество слов, вы можете создать фрейм данных для количества слов со следующим кодом:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_QZhGgP3x91"
      },
      "source": [
        "word_freq_df = pd.DataFrame(X_train_cv.toarray(), columns=cv.get_feature_names())\n",
        "word_freq_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция [`sum()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html) будет суммировать по колонкам:"
      ],
      "metadata": {
        "id": "kHUvoMmELVW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_freq_df.sum()"
      ],
      "metadata": {
        "id": "jt89lMm2LNgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_words_df = pd.DataFrame(word_freq_df.sum()).sort_values(0, ascending=False)\n",
        "top_words_df.head()"
      ],
      "metadata": {
        "id": "4x47HrnlLFJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Мучаем Байса"
      ],
      "metadata": {
        "id": "0J4g-UpKMMwf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXvR4rZEggDU"
      },
      "source": [
        "\n",
        "\n",
        "Теперь мы готовы подогнать [Мультиномиальную наивную байесовскую классификаторную](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) модель к нашим обучающим данным и использовать ее для прогнозирования меток тестовых данных:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vktNhcO4Bfq"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train_cv, y_train)\n",
        "predictions = naive_bayes.predict(X_test_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Проверяем результаты"
      ],
      "metadata": {
        "id": "p4mRAjN1MeJG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MllfxoRdiGDo"
      },
      "source": [
        "\n",
        "Давайте посмотрим, как модель работает с тестовыми данными:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnpO0SzO4D3J"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "print('Accuracy score: ', accuracy_score(y_test, predictions)) \n",
        "print('Precision score: ', precision_score(y_test, predictions.astype(int), average='macro'))\n",
        "print('Recall score: ', recall_score(y_test, predictions.astype(int), average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[`Accuracy score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) (доля правильных ответов алгоритма) - это оценка точности классификации. В классификации с несколькими метками эта функция вычисляет точность подмножества: набор меток, предсказанный для выборки, должен точно соответствовать соответствующему набору меток в `y_true`.\n",
        "\n",
        "[`Precision score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html) (точность) - это отношение  `tp / (tp + fp)`, где `tp` - количество истинных срабатываний и `fp` количество ложных срабатываний. Точность — это интуитивно способность классификатора не маркировать отрицательный образец как положительный. Лучшее значение равно `1`, а худшее значение равно `0`.\n",
        "\n",
        "\n",
        "[`Recall score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) (полонота) - это отношение `tp / (tp + fn)`, где `tp` - количество истинных положительных результатов и `fn` количество ложных отрицательных результатов. Под отзывом понимается интуитивно способность классификатора находить все положительные образцы.\n",
        "\n",
        "Подробнее про метрики [здесь](https://habr.com/ru/company/ods/blog/328372/).\n",
        "\n"
      ],
      "metadata": {
        "id": "eK1RJBH7NNho"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3Mtpk6BiS0J"
      },
      "source": [
        "Чтобы понять эти оценки, `hotmap` помогает увидеть разбивку с помощью [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpU0WxpV5YbJ"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "sns.heatmap(cm, square=True, annot=True, cmap='RdBu', fmt=\"d\",\n",
        "xticklabels=np.arange(1,6).astype(str), yticklabels=np.arange(1,6).astype(str))\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Пробуем на своих примерах"
      ],
      "metadata": {
        "id": "fuuTX6uvR1L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_check = np.array([\"I don't like this thing, it sucks.\", \n",
        "                    \"I hate this thing. I don not like her. I do not know what to do. This thing is not worth the money.\",\n",
        "                    \"I love these clothes\",\n",
        "                    \"The dress is too small for me.\",\n",
        "                    \"It was huge, shapeless.\"])\n",
        "X_check_cv = cv.transform(X_check)\n",
        "predictions_check = naive_bayes.predict(X_check_cv)\n",
        "predictions_check"
      ],
      "metadata": {
        "id": "bouR5ZAmSEZF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}