{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "individual_work.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Знакомство с нейронными сетями (решение задач с MNIST)"
      ],
      "metadata": {
        "id": "VgUtLKtnAs0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание"
      ],
      "metadata": {
        "id": "Ym9TCEObA468"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot2VaHJ44JUF"
      },
      "source": [
        "Поробуйте изменить модель и процесс обучения в соответсвии с разделами \"Эксперименты с..\". Сделайте вывод о том, какие эксперименты были удачными\n",
        "\n",
        "Читать здесь: [Эксперименты с многослойным перцептроном в Keras](http://deep.uran.ru/wiki/index.php?title=%D0%AD%D0%BA%D1%81%D0%BF%D0%B5%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D1%82%D1%8B_%D1%81_%D0%BC%D0%BD%D0%BE%D0%B3%D0%BE%D1%81%D0%BB%D0%BE%D0%B9%D0%BD%D1%8B%D0%BC_%D0%BF%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD%D0%BE%D0%BC_%D0%B2_Keras)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d20tnAzAR-4"
      },
      "source": [
        "try:\n",
        "  # Colab only\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAvDVB2OATv8"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow и tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Вспомогательные библиотеки\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58oipnDNAb0H"
      },
      "source": [
        "## Подключение Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p94dJWd9AXxx"
      },
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdeuOI7WAnM8"
      },
      "source": [
        "## Загрузка обучающих и тестовых примеров из MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4aKG5-jAohP"
      },
      "source": [
        "nb_classes = 10\n",
        "\n",
        "# the data, shuffled and split between tran and test sets\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5OEwZqTA50O"
      },
      "source": [
        "Давайте посмотрим на формат данных перед обучением модели. Воспользовавшись `shape` мы видим, что в тренировочном датасете 60,000 изображений, каждое размером 28 x 28 пикселей:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHeI0XrUAwaF"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aLc87R0BjD0"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Предобработка данных"
      ],
      "metadata": {
        "id": "4e9ILQy-A_7X"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W7tjyA4BFP0"
      },
      "source": [
        "\n",
        "\n",
        "Данные должны быть предобработаны перед обучением нейросети. Если вы посмотрите на первое изображение в тренировочном сете вы увидите, что значения пикселей находятся в диапазоне от 0 до 255:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTKURARLBEm1"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHM5VadDBVpw"
      },
      "source": [
        "Мы масштабируем эти значения к диапазону от 0 до 1 перед тем как скормить их нейросети. Для этого мы поделим значения на 255. Важно, чтобы тренировочный сет и проверочный сет были предобработаны одинаково:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VjrS5gHBU62"
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jSq3eytBvRb"
      },
      "source": [
        "class_names = np.arange(10)\n",
        "class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K8UhnWyBneh"
      },
      "source": [
        "Чтобы убедиться, что данные в правильном формате и мы готовы построить и обучить нейросеть, выведем на экран первые 25 изображений из тренировочного сета и отобразим под ними наименования их классов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvxMRoBaBpY0"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание сети - однослойного перцептрона"
      ],
      "metadata": {
        "id": "Vh0P6hwWBB9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Описание модели"
      ],
      "metadata": {
        "id": "1aTxu5j2BESl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBjlySsPCByC"
      },
      "source": [
        "\n",
        "\n",
        "Создадим однослойный перцептрон в Keras. Входные примеры базы MNIST являются изображениями 28x28 пикселей, которые преобразованы в вектора длины 784 через слой `Flatten` (его мы не будем считать как за слой, он для нас лишь входной вектор). Мы создаем слой, состоящий из 10 нейронов, в котором каждый нейрон связян со всеми входами. Такие слои в Keras называются \"Dense\". Мы задаём функцию активации выходного слоя - `softmax`, которая применяется для задач классификации. То есть, на выходе будет выдаваться 10 неотрицательных чисел, сумма которых равна 1, которые характеризуют вероятности того, что входное изображение является цифрой 0,1,...9.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TAJ9QeiCqah"
      },
      "source": [
        "model1 = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model1.summary() #Print model info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Компиляция модели"
      ],
      "metadata": {
        "id": "B_YqYeXTBF-3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L8d69dtCK1j"
      },
      "source": [
        "\n",
        "\n",
        "Теперь, скомпилируем модель. Это значит, что мы построим функцию Python, которая позволит вычислять результат работы сети на входном векторе, вызывая функцию `model.predict(...)`. Но, главное, посчитается функция вычисления градиента функции ошибки по весам сети, что необходимо для осуществления обучения (настройки) параметров сети:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ1TLr9VCMj-"
      },
      "source": [
        "model1.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь `adam` - тип градиентного спуска, `categorical_crossentropy` - функция штрафа, кроссэнтропия, которую следует использовать для задач классификации, как у нас, `metrics=['accuracy']` значит, что мы будем вычислять в модели не только функцию штрафа, но и точность работы, то есть, число правильно классифицированных примеров."
      ],
      "metadata": {
        "id": "xGwxRVR8BI3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение модели"
      ],
      "metadata": {
        "id": "jxAJU9pDBJ5w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLwjYbRYGALH"
      },
      "source": [
        "\n",
        "\n",
        "Это самая ресурсоемкая операция. Мы выполняем обучение \"пачками\" (mini-batch) по `batch_size=128 примеров`. При этом, осуществляет `epoch=5` проходов по всем входным примерам.\n",
        "\n",
        "Другие варианты режима обучения:\n",
        "\n",
        "* **по одному примеру** - медленная сходимость, и алгоритм \"не видит\" хороших минимумов,\n",
        "* **по всем примерам сразу** - трудоемко, и сходимость к локальному минимуму и склонностьк переобучению.\n",
        "\n",
        "А обработка `mini-batch` - промежуточный вариант, который называется градиентным стохастическим спуском."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPZFWjpECTlF"
      },
      "source": [
        "model1.fit(train_images, train_labels, batch_size=128, verbose=2, epochs=10, validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAMGdgTAHRUe"
      },
      "source": [
        "Здесь `loss` - функция ошибки, `acc` - точность на обучающей выборке, `val_loss` и `val_acc` - на тестовой выборке."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Эксперименты с однослойной сетью"
      ],
      "metadata": {
        "id": "yDDNUNuoBNSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Увеличение числа прогонов"
      ],
      "metadata": {
        "id": "l746O_YbBQMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Измените количество прогонов обучающих до 20. Изменится ли что-нибудь при  увеличении числа прогонов?"
      ],
      "metadata": {
        "id": "uJr08xIjBSGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Выключение нормализации входных данных"
      ],
      "metadata": {
        "id": "CrG0jIBlBT2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Закомментируем нормализацию входных яркостей:\n",
        "\n",
        "```python\n",
        "# train_images = train_images / 255.0\n",
        "# test_images = test_images / 255.0\n",
        "```\n",
        "\n",
        "Как сказывается это на процесс обучения?"
      ],
      "metadata": {
        "id": "g0-noAj6BYqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Верните все в исходное состояние!"
      ],
      "metadata": {
        "id": "F3n1yRbABaDF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWVqhhxENE0R"
      },
      "source": [
        "\n",
        "\n",
        "Прежде чем двигаться дальше, раскомментируйте нормализацию входных яркостей обратно и перезапустите блокнот `Runtime -> Restart and run all...`:\n",
        "\n",
        "```python\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Двуслойный перцептрон"
      ],
      "metadata": {
        "id": "A1W0pP9gBchC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMa1CZqwPJjB"
      },
      "source": [
        "\n",
        "\n",
        "Создадим теперь сеть с двумя \"плотными\" слоями.\n",
        "\n",
        "Первый слой (\"скрытый слой\") будет состоять из 100 нейронов, соединенных со всеми входами. Функция активации будет `relu` - это самая популярная функция активации для скрытых слоев.\n",
        "Второй слой будет состоять из 10 нейронов с функцией активации `softmax`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHTsY9rjOWOg"
      },
      "source": [
        "model2 = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.summary() #Print model info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtbqEkDyRrLq"
      },
      "source": [
        "model2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOnW9ijQRmyW"
      },
      "source": [
        "model2.fit(train_images, train_labels, batch_size=128, verbose=2, epochs=10, validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa3wzpFnQeSZ"
      },
      "source": [
        "В этом случае, у сети будет уже 79510 параметров (в однослойном случае было 7850).\n",
        "\n",
        "Из теоремы Колмогорова следует, *что любую функцию можно аппроксимировать с любой точностью, используя двуслойную сеть, задав достаточно много нейронов в первом слое*. Правда, эта теорема не говорит о том, что обучение сети сойдется к нужной аппроксимации, но указывает, что теоретически, достаточно двух слоев.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Эксперименты с двухслойной сетью"
      ],
      "metadata": {
        "id": "ZeUuz2cKBhGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Изменение количество нейронов в слое"
      ],
      "metadata": {
        "id": "i5OvutP0BiqU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gObkEucURfaZ"
      },
      "source": [
        "\n",
        "\n",
        "Попробуйте поиграться с количеством нейронов в скрытом слое. Изменится ли точность на тестовой выборке?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5gT1FH6R7bZ"
      },
      "source": [
        "## Трехслойный перцептрон"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавьте еще один скрытый слой из 200 нейронов после первого слоя двуслойной сети."
      ],
      "metadata": {
        "id": "b8r-bizsCZ4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Эксперименты с двухслойной сетью"
      ],
      "metadata": {
        "id": "dlvFI-p2CZBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Изменение количество нейронов в слое"
      ],
      "metadata": {
        "id": "iA5oorj2CbsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуйте поиграться с количеством нейронов в скрытом слое. Изменится ли точность на тестовой выборке?"
      ],
      "metadata": {
        "id": "aVeegTz_CdwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Изменение функций активации"
      ],
      "metadata": {
        "id": "zc_eEJTpCjQa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vswQQzSgSTpP"
      },
      "source": [
        "\n",
        "\n",
        "Попробуйте изменить функцию активации в скрытых слоях `sigmoid` или `tanh` Подробнее о функциях активации см. [здесь](https://keras.io/activations/). Как это скажется на процессе обучения, валидации?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выводы"
      ],
      "metadata": {
        "id": "x1aorN5dCmoE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DjKO2jaSdo4"
      },
      "source": [
        "Мы получили следующие результаты:\n",
        "\n",
        "* **Однослойная сеть**: `/вставь сюда что получилось/` параметров, точность `/вставь сюда что получилось/`%\n",
        "* **Двуслойная сеть**: `/вставь сюда что получилось/` параметров, точность `/вставь сюда что получилось/`%\n",
        "* **Трехслойная сеть**: `/вставь сюда что получилось/` параметров, точность `/вставь сюда что получилось/`%\n",
        "\n",
        "\n",
        "Из таблицы следует, что двуслойная \"плотная\" сеть работает  `/лучше/худше/также/` однослойной, но трехслойная сеть работает `/лучше/худше/также/` двухслойной.\n",
        "\n",
        "Может возникнуть эффект переобучения от увеличение количества слоев?"
      ]
    }
  ]
}