{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workshop_MainFlow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Классификация и линейная регрессия со scikit-learn"
      ],
      "metadata": {
        "id": "Jf8hONl09_0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 2. Алгоритм к-ближайших соседей."
      ],
      "metadata": {
        "id": "0tIFK4MHUvKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "kNN расшифровывается как k Nearest Neighbor или k Ближайших Соседей — это один из самых простых алгоритмов классификации, также иногда используемый в задачах регрессии."
      ],
      "metadata": {
        "id": "eEF8oEZ4UyLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Описание метода"
      ],
      "metadata": {
        "id": "qzsnSFk3U4fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Описание метода представлено здесь:\n",
        "\n",
        "* RUS: [Алгоритм k-ближайших соседей // Основы машинного обучения](https://youtu.be/2ufg0G-0RRc)\n",
        "* RUS: [Алгоритм K-ближайших соседей в Python и Scikit-Learn](https://pythobyte.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn-31cdde4d/)\n",
        "* RUS: [Алгоритм k-ближайших соседей](http://datascientist.one/k-nearest-neighbors-algorithm/)\n",
        "* RUS: [Основные метрики задач классификации в машинном обучении](https://webiomed.ai/blog/osnovnye-metriki-zadach-klassifikatsii-v-mashinnom-obuchenii/)\n",
        "* RUS: [Классификатор kNN](https://habr.com/ru/post/149693/)\n",
        "* ENG: [Обучение модели машинного обучения с помощью перекрестной проверки](https://docs.microsoft.com/ru-ru/dotnet/machine-learning/how-to-guides/train-machine-learning-model-cross-validation-ml-net)\n",
        "* ENG: [Разница между K-средним и K-ближайшим соседом](http://www.devcoons.com/difference-k-means-k-nearest-neighbor-algorithm/)\n",
        "* RUS: [Метод k-ближайших соседей (K-nearest neighbor)](https://wiki.loginom.ru/articles/k-nearest-neighbor.html)"
      ],
      "metadata": {
        "id": "WDd4-7LxVCaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "GYvjHz7Q-d8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В ячейке ниже загружаем kaggle.json для вашей среды выполнения Colab, полученный на https://www.kaggle.com/.\n",
        "\n"
      ],
      "metadata": {
        "id": "HDs1uTQI_Dq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "s5Q6BIwM_EWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание"
      ],
      "metadata": {
        "id": "_9_A9_6LVI3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Выберите набор данных (датасет) для решения задачи классификации или регресии.\n",
        "1. В случае необходимости проведите удаление или заполнение пропусков и кодирование категориальных признаков.\n",
        "1. С использованием метода `train_test_split` разделите выборку на обучающую и тестовую.\n",
        "1. Обучите модель ближайших соседей для произвольно заданного гиперпараметра `K`. Оцените качество модели с помощью трех подходящих для задачи метрик.\n",
        "1. Постройте модель и оцените качество модели с использованием кросс-валидации. Проведите эксперименты с тремя различными стратегиями кросс-валидации.\n",
        "1. Произведите подбор гиперпараметра `K` с использованием `GridSearchCV` и кросс-валидации.\n",
        "1. Повторите пункт 4 для найденного оптимального значения гиперпараметра `K`. Сравните качество полученной модели с качеством модели, полученной в пункте 4.\n",
        "1. Постройте кривые обучения и валидации.\n"
      ],
      "metadata": {
        "id": "a2uYTLtbVM4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Выбор датасета"
      ],
      "metadata": {
        "id": "FXZD6zsvVUek"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlW1_ggviXvq"
      },
      "source": [
        "Для самостоятельной работы предлагается выбрать один из датасетов\n",
        "\n",
        "* [Glass Classification](https://www.kaggle.com/uciml/glass)\n",
        "\n",
        "* [Iris Flower Dataset](https://www.kaggle.com/arshid/iris-flower-dataset)\n",
        "\n",
        "В данном блокноте рассматривается [Classifying wine varieties](https://www.kaggle.com/brynja/wineuci).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avJ8vPHED4jl"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import learning_curve, validation_curve\n",
        "from sklearn.model_selection import KFold, RepeatedKFold, LeaveOneOut, LeavePOut, ShuffleSplit, StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.metrics import roc_curve,confusion_matrix, roc_auc_score, accuracy_score, balanced_accuracy_score\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# 'Магическая' функция matplotlib\n",
        "%matplotlib inline \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получаем датасет:"
      ],
      "metadata": {
        "id": "_SuWh4XMVmkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/\n",
        "!mkdir wineuci\n",
        "!cd /content/wineuci"
      ],
      "metadata": {
        "id": "E2zbxeswWDyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyCHdAwpwZaY"
      },
      "source": [
        "!kaggle datasets download -d brynja/wineuci -p /content/wineuci"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/wineuci/wineuci.zip -d /content/wineuci"
      ],
      "metadata": {
        "id": "Dq9-JDfuWRbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVjr7QBwwjt6"
      },
      "source": [
        "### Загрузка набора данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le2MYGoTwear"
      },
      "source": [
        "CURENT_DIR = '/content/wineuci'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzFf0jUSwhA4"
      },
      "source": [
        "# Загрузить набор данных\n",
        "data = pd.read_csv(CURENT_DIR+'/Wine.csv', delimiter=',', encoding = \"ISO-8859-1\", \n",
        "                     names = ('Class','Alcohol','Malic acid','Ash','Alcalinity of ash',\n",
        "                                'Magnesium','Total phenols','Flavanoids','Nonflavanoid phenols',\n",
        "                                'Proanthocyanins','Color intensity','Hue','OD','Proline')) \n",
        "\n",
        "# Распечать первые 5 строк фрейма данных\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU95Yg_AwwPh"
      },
      "source": [
        "### Первичный осмотр выбранного датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnfElLpbwnu6"
      },
      "source": [
        "# Список колонок с типами данных\n",
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJy79-jMwu5M"
      },
      "source": [
        "for col in data.columns:\n",
        "    print('{} - {}'.format(col, data[data[col].isnull()].shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtrIsGX5w72h"
      },
      "source": [
        "data.shape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF1CmS8vw7US"
      },
      "source": [
        "### Разделяем тестовые и данные для обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsB4N7qIxC2k"
      },
      "source": [
        "X = data.drop('Class',axis=1).values\n",
        "y = data['Class'].values\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42, stratify=y)\n",
        "print('X_train: {}  y_train: {}'.format(X_train.shape, y_train.shape))\n",
        "print('X_test: {}  y_test: {}'.format(X_test.shape, y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение модели ближайших соседей"
      ],
      "metadata": {
        "id": "lVdgXWWGXli8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRX2GReuxEpm"
      },
      "source": [
        "**Оптимизация гиперпараметров** — задача машинного обучения по выбору набора оптимальных гиперпараметров для обучающего алгоритма.\n",
        "\n",
        "Одни и те же виды моделей машинного обучения могут требовать различные предположения, веса или скорости обучения для различных видов данных. Эти параметры называются гиперпараметрами и их следует настраивать так, чтобы модель могла оптимально решить задачу обучения.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfOgqTgTxTwb"
      },
      "source": [
        "# Настройка массивов для хранения точности обучения и тестирования\n",
        "neighbors = np.arange(1,14)\n",
        "len(neighbors) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF30BQOWxfl8"
      },
      "source": [
        "### Обучение при различном количестве соседей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZrieWhmxiVD"
      },
      "source": [
        "# Вернуть новый массив заданной формы и типа без инициализации записей.\n",
        "# При первом вызове функции все элементы окажутся случайными:\n",
        "train_accuracy =np.empty(len(neighbors))\n",
        "test_accuracy = np.empty(len(neighbors))\n",
        "\n",
        "for i,k in enumerate(neighbors):\n",
        "    # Настройка классификатора Knn с K соседями\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    \n",
        "    # Обучить модель\n",
        "    knn.fit(X_train, y_train)\n",
        "    \n",
        "    # Вычислить точность на тренировочном наборе\n",
        "    train_accuracy[i] = knn.score(X_train, y_train)\n",
        "    \n",
        "    # Вычислить точность на тестовом наборе\n",
        "    test_accuracy[i] = knn.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fgok7qtxlfV"
      },
      "source": [
        "# Построить набор\n",
        "plt.title('k-NN Различное количество соседей')\n",
        "plt.plot(neighbors, train_accuracy, label='Точность на обучающем наборе')\n",
        "plt.plot(neighbors, test_accuracy, label='Точность на тестовом наборе')\n",
        "plt.legend()\n",
        "plt.xlabel('Количество соседей')\n",
        "plt.ylabel('Точность')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Изучение работы KNeighborsClassifier"
      ],
      "metadata": {
        "id": "FhywDJ3iXsyF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdLVGlGjw4_w"
      },
      "source": [
        "\n",
        "\n",
        "Классификатор, реализующий голосование ближайших соседей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_IXI6CkyuVp"
      },
      "source": [
        "# Настройка классификатора knn с K соседями. Указываем искать 10 групп-соседей\n",
        "knn = KNeighborsClassifier(n_neighbors=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtvQQkXfywo2"
      },
      "source": [
        "# Обучаем модель\n",
        "knn.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCvoe06py0x3"
      },
      "source": [
        "# Приведет для примера:\n",
        "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
        "           weights='uniform')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E1_uYQgy4HE"
      },
      "source": [
        "# Получить точность. Примечание: в случае алгоритмов классификации метод оценки представляет собой точность.\n",
        "knn.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDQpNgNgz_B9"
      },
      "source": [
        "См подробнее об [Precision, recall и F-мера](https://habr.com/ru/company/ods/blog/328372/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fxkynIfzQsR"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# precision - точность \n",
        "y_pred = knn.predict(X_test)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPpEvPzuzdz-"
      },
      "source": [
        "### Точность"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpuC1p9Vzgql"
      },
      "source": [
        "cl1_1 = KNeighborsClassifier(n_neighbors=7)\n",
        "cl1_1.fit(X_train, y_train)\n",
        "target1_1 = cl1_1.predict(X_test)\n",
        "accuracy_score(y_test, target1_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L32YwjaI0OT2"
      },
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "confusion_matrix(y_test,y_pred)\n",
        "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ROC-кривая"
      ],
      "metadata": {
        "id": "0C0URcGlX53O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8-1m2UQ0mvk"
      },
      "source": [
        "\n",
        "\n",
        "ROC-кривая (Receiver Operator Characteristic) – кривая, которая наиболее часто используется для представления результатов бинарной классификации в машинном обучении. Название пришло из систем обработки сигналов. Поскольку классов два, один из них называется классом с положительными исходами, второй – с отрицательными исходами. ROC-кривая показывает зависимость количества верно классифицированных положительных примеров от количества неверно классифицированных отрицательных примеров. В терминологии ROC-анализа первые называются истинно положительным, вторые – ложно отрицательным множеством. При этом предполагается, что у классификатора имеется некоторый параметр, варьируя который, мы будем получать то или иное разбиение на два класса. Этот параметр часто называют порогом, или точкой отсечения (cut-off value). В зависимости от него будут получаться различные величины ошибок I и II рода.\n",
        "\n",
        "Подробнее см. [здесь](https://basegroup.ru/community/articles/logistic).\n",
        "\n",
        "И еще см. [здесь](https://habr.com/ru/post/228963/), тут понятнее.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdgkeKA_0t_o"
      },
      "source": [
        "y_pred_proba = knn.predict_proba(X_test)[:,1]\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba, pos_label=2)\n",
        "\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.plot(fpr,tpr, label='Knn')\n",
        "plt.xlabel('fpr')\n",
        "plt.ylabel('tpr')\n",
        "plt.title('Knn(n_neighbors=7) ROC curve')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m024XhMwPzJ"
      },
      "source": [
        "### Кросс-валидация"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Кросс-валидация](https://neerc.ifmo.ru/wiki/index.php?title=Кросс-валидация)"
      ],
      "metadata": {
        "id": "6BHT33FAIjL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Перекрестная проверка K-Fold - Введение в машинное обучение](https://youtu.be/TIgfjmp-4BA)"
      ],
      "metadata": {
        "id": "jdT-7lw1HODH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPoSMYRI1kdp"
      },
      "source": [
        "param_grid = {'n_neighbors':np.arange(1,14)}\n",
        "knn = KNeighborsClassifier()\n",
        "knn_cv= GridSearchCV(knn,param_grid,cv=5)\n",
        "knn_cv.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`GridSearchCV` – это очень мощный инструмент для автоматического подбирания параметров для моделей машинного обучения. GridSearchCV находит наилучшие параметры, путем обычного перебора: он создает модель для каждой возможной комбинации параметров. Важно отметить, что такой подход может быть весьма времязатратным.\n",
        "\n",
        "Подробнее [здесь](https://vc.ru/ml/147132-kak-avtomaticheski-podobrat-parametry-dlya-modeli-mashinnogo-obucheniya-ispolzuem-gridsearchcv)."
      ],
      "metadata": {
        "id": "aXNd3SzyHkKB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u734HH6D1rbx"
      },
      "source": [
        " GridSearchCV(cv=5, error_score='raise-deprecating',\n",
        "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
        "           weights='uniform'),\n",
        "       n_jobs=None,\n",
        "       param_grid=param_grid,\n",
        "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
        "       scoring=None, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FIbasdw1tCV"
      },
      "source": [
        "knn_cv.best_score_ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xgFqUf21t3A"
      },
      "source": [
        "knn_cv.best_params_ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-fold"
      ],
      "metadata": {
        "id": "yGsL5SOkYnbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Разновидности скользящего контроля](http://www.machinelearning.ru/wiki/index.php?title=CV)\n"
      ],
      "metadata": {
        "id": "C_ZqRYFAINei"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-wrRyGr1v3_"
      },
      "source": [
        "\n",
        "\n",
        "Данная стратегия работает в соответствии с определением кросс-валидации.\n",
        "\n",
        "Каждой стратегии в `scikit-learn` ставится в соответствии специальный класс-итератор, который может быть указан в качестве параметра cv функций `cross_val_score` и `cross_validate`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VnYFjsM13QB"
      },
      "source": [
        "scores = cross_val_score(KNeighborsClassifier(n_neighbors=4), \n",
        "                         X, y, \n",
        "                         cv=KFold(n_splits=5))\n",
        "\n",
        "# Значение метрики accuracy для 5 фолдов\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpG_1ax315Zx"
      },
      "source": [
        "# Усредненное значение метрики accuracy для 5 фолдов\n",
        "np.mean(scores) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcaC-JiI161u"
      },
      "source": [
        "scoring = {'precision': 'precision_weighted', \n",
        "           'recall': 'recall_weighted',\n",
        "           'f1': 'f1_weighted'}\n",
        "\n",
        "scores = cross_validate(KNeighborsClassifier(n_neighbors=4), \n",
        "                        X, y, scoring=scoring, \n",
        "                        cv=KFold(n_splits=5), return_train_score=True)\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leave One Out (LOO)"
      ],
      "metadata": {
        "id": "cBnEPFzzYrb6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7swV0-IS2H2Z"
      },
      "source": [
        "\n",
        "\n",
        "В тестовую выборку помещается единственный элемент (One Out). Количество фолдов в этом случае определяется автоматически и равняется количеству элементов.\n",
        "\n",
        "Данный метод более ресурсоемкий чем KFold.\n",
        "\n",
        "Существует эмпирическое правило, что вместо Leave One Out лучше использовать KFold на 5 или 10 фолдов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu7QrILw2J_p"
      },
      "source": [
        "loo = LeaveOneOut()\n",
        "loo.get_n_splits(X)\n",
        "\n",
        "for train_index, test_index in loo.split(X):\n",
        "   y_train, y_test = y[train_index], y[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzad3iQf2NbX"
      },
      "source": [
        "### Repeated K-Fold\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMrCSuGS2MPS"
      },
      "source": [
        "scores2 = cross_val_score(KNeighborsClassifier(n_neighbors=4), \n",
        "                         X, y, \n",
        "                         cv=RepeatedKFold(n_splits=5, n_repeats=2))\n",
        "scores2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Em7VWpn2WOF"
      },
      "source": [
        "### Обучение с оптимальным K"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_7obDw12Vdi"
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42, stratify=y)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "knn.fit(X_train,y_train)\n",
        "knn.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEdT6_8N2Z59"
      },
      "source": [
        "### Построение кривых обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUDP3SQg2cUf"
      },
      "source": [
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGBsCiQN2dti"
      },
      "source": [
        "plot_learning_curve(KNeighborsClassifier(n_neighbors=4), 'n_neighbors=4', \n",
        "                    X_train, y_train, cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75PybKn52mmQ"
      },
      "source": [
        "### Построение кривой валидации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QliQS1AM2lui"
      },
      "source": [
        "def plot_validation_curve(estimator, title, X, y, \n",
        "                          param_name, param_range, cv, \n",
        "                          scoring=\"accuracy\"):\n",
        "                                                   \n",
        "    train_scores, test_scores = validation_curve(\n",
        "        estimator, X, y, param_name=param_name, param_range=param_range,\n",
        "        cv=cv, scoring=scoring, n_jobs=1)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel(param_name)\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.0, 1.1)\n",
        "    lw = 2\n",
        "    plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
        "                 color=\"darkorange\", lw=lw)\n",
        "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
        "                     color=\"darkorange\", lw=lw)\n",
        "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
        "                 color=\"navy\", lw=lw)\n",
        "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
        "                     color=\"navy\", lw=lw)\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_gRei1R2o6A"
      },
      "source": [
        "n_range = np.array(range(5,55,5))\n",
        "plot_validation_curve(KNeighborsClassifier(n_neighbors=4), 'knn', \n",
        "                      X_train, y_train, \n",
        "                      param_name='n_neighbors', param_range=n_range, \n",
        "                      cv=5, scoring=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}