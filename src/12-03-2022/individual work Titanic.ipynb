{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"individual work Titanic.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Титаник - Машинное обучение после катастрофы"],"metadata":{"id":"WQw1nwTnny95"}},{"cell_type":"markdown","source":["В данном блокноте нас будет интересовать датасет [Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic/data).\n"],"metadata":{"id":"t3KAUBMan6sL"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"zl4T-Xb2oDzc"}},{"cell_type":"markdown","source":["Обучающий набор следует использовать для построения моделей машинного обучения. Для обучающего набора мы предоставляем результат (также известный как \"основная истина\") для каждого пассажира. Ваша модель будет основана на таких \"особенностях\", как пол и класс пассажиров. Вы также можете использовать разработку функций для создания новых функций.\n","\n","Тестовый набор следует использовать, чтобы увидеть, насколько хорошо ваша модель работает с невидимыми данными. Для тестового набора мы не предоставляем основную истину для каждого пассажира. Ваша задача - предсказать эти результаты. Для каждого пассажира в тестовом наборе используйте обученную модель, чтобы предсказать, выжил ли он после крушения \"Титаника\".\n"],"metadata":{"id":"YdV4eV_doD0b"}},{"cell_type":"code","metadata":{"id":"9KhtR30ectl7"},"source":["try:\n","  # Colab only\n","  %tensorflow_version 2.x\n","except Exception:\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6TDaozBbeQ63"},"source":["import tensorflow as tf\n","\n","import tensorflow_datasets as tfds\n","\n","print(\"Version: \", tf.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLh1pg69hn7N"},"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import rcParams"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9Si-pD3hsLM"},"source":["%matplotlib inline\n","rcParams['figure.figsize'] = 10,8\n","sns.set(style='whitegrid', palette='muted',\n","        rc={'figure.figsize': (15,10)})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vsYsuiiCht_a"},"source":["import os\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from keras.wrappers.scikit_learn import KerasClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Загрузка датасета с Kaggle"],"metadata":{"id":"UzbSuL3tldMA"}},{"cell_type":"markdown","source":["В ячейке ниже загружаем kaggle.json для вашей среды выполнения Colab, полученный на https://www.kaggle.com/."],"metadata":{"id":"uCGIZl1NliFE"}},{"cell_type":"code","metadata":{"id":"mtNDOxwx8B_4"},"source":["!pip install kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QO_LOz5eojwv"},"source":["В ячейке ниже загружаем kaggle.json для вашей среды выполнения Colab, полученный на https://www.kaggle.com/."]},{"cell_type":"code","metadata":{"id":"5Uh-B8yAmYQ4"},"source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","  \n","# Then move kaggle.json into the folder where the API expects to find it.\n","!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Создаем папку, в которую выгрузим датасет:"],"metadata":{"id":"F67S1U34ltmb"}},{"cell_type":"code","source":["!cd /content/\n","!mkdir dataset\n","!cd /content/dataset"],"metadata":{"id":"BKW2uqbulvoQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SZ-8aJ5OopjP"},"source":["Загрузим интересующий нас датасет"]},{"cell_type":"code","metadata":{"id":"KHlyqMv_mNLZ"},"source":["!kaggle competitions download -c titanic -p /content/dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip  /content/dataset/titanic.zip -d /content/dataset"],"metadata":{"id":"uZhdGHIDpWug"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vmk4wY0MqP40"},"source":["Проверяем наличие:"]},{"cell_type":"code","metadata":{"id":"y-c1YSuWoY6e"},"source":["!ls /content/dataset/ -lsa"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P-mN6ZPtn1gi"},"source":["## Разворачивание датасета"]},{"cell_type":"code","metadata":{"id":"SyoDPT8drjB1"},"source":["# Load data as Pandas dataframe\n","train = pd.read_csv('/content/dataset/test.csv')\n","test = pd.read_csv('/content/dataset/train.csv')\n","data = pd.concat([train, test], axis=0, sort=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aNf8JPNyujKl"},"source":["## Первичный анализ"]},{"cell_type":"code","metadata":{"id":"lKKaqemjr3zK"},"source":["data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDGhQ8vJsSWF"},"source":["def display_all(data):\n","    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n","        display(data)\n","        \n","display_all(data.describe(include='all').T)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z43TmeTwua0f"},"source":["data.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LW6r-QcTuenv"},"source":["data.nunique() # количество уникальных значений для каждого столбца "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DSDRIjC61tBv"},"source":["data.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZHkpZQglutXI"},"source":["## Кодирование категориальных признаков"]},{"cell_type":"code","metadata":{"id":"MaFAJtwK0vZs"},"source":["sns.countplot(x='Sex', data=data, palette='hls', hue='Survived')\n","plt.xticks(rotation=45)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pFIeD9_82TXR"},"source":["Мы воспользуемся методом [`pandas.DataFrame.astype`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html) для преобразования в категориальный тип, а затем возьмем коды полученных объектов."]},{"cell_type":"code","metadata":{"id":"2-5rNd802B2v"},"source":["# convert to cateogry dtype\n","data['Sex'] = data['Sex'].astype('category')\n","# convert to category codes\n","data['Sex'] = data['Sex'].cat.codes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3gN1YPiA2JqB"},"source":["data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3E22J-D3jhy"},"source":["data['Title'] = data['Name'].str.split(',',1).str[1].str.split('.',1).str[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Eepqasg59Md"},"source":["Выбрасываем переменные, которые мы не будем использовать"]},{"cell_type":"code","metadata":{"id":"neUvPZDI5w8B"},"source":["data.drop(['Cabin', 'Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fsYFbNZA3WeM"},"source":["Воспользуемся [`pandas.get_dummies`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) для получение индикаторных переменных"]},{"cell_type":"code","metadata":{"id":"F3xpOeP93Uvy"},"source":["# подмножество всех категориальных переменных, которые должны быть закодированы\n","categorical = ['Embarked', 'Title']\n","\n","for var in categorical:\n","    data = pd.concat([data, \n","                    pd.get_dummies(data[var], prefix=var)], axis=1)\n","    del data[var]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxCKUFWx699F"},"source":["data.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Импьютация пропущенных данных"],"metadata":{"id":"GftPruZXqKed"}},{"cell_type":"markdown","metadata":{"id":"djlcOXS6DcU_"},"source":["\n","\n","Воспользуемся [`sklearn.impute.SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer)."]},{"cell_type":"code","metadata":{"id":"ay-5Sei1Cxw9"},"source":["from sklearn.impute import SimpleImputer\n","imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b24Nj-aDC4PG"},"source":["imp_num = SimpleImputer(missing_values=np.nan, strategy='mean')\n","data['Age']  = imp_num.fit_transform(data[['Age']])\n","data['Fare']  = imp_num.fit_transform(data[['Fare']])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Масштабирование непрерывных переменных"],"metadata":{"id":"bmL-zKJCqM7d"}},{"cell_type":"markdown","metadata":{"id":"PUF9hXG27lZT"},"source":["\n","\n","Идея [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler) заключается в том, что он преобразует ваши данные так, что их распределение будет иметь среднее значение `0` и стандартное отклонение `1`.\n"]},{"cell_type":"code","metadata":{"id":"JSfPTf8M7LZY"},"source":["continuous = ['Age', 'Fare', 'Parch', 'Pclass', 'SibSp']\n","\n","scaler = StandardScaler()\n","\n","for var in continuous:\n","    data[var] = data[var].astype('float64')\n","    data[var] = scaler.fit_transform(data[var].values.reshape(-1, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JeAhA4Xr73kd"},"source":["display_all(data.describe(include='all').T)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6LI9lpP8CmF"},"source":["data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nE7QY5kh8I6C"},"source":["data.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Обучение нейронных сетей"],"metadata":{"id":"kbOPUjXkqUOV"}},{"cell_type":"markdown","metadata":{"id":"cZN5ADZCDzs6"},"source":["\n","\n","Теперь все, что осталось, - это передать наши данные, которые были очищены, закодированы и масштабированы в нашу нейронную сеть.\n","\n","Но сначала нам нужно разделить DataFrame обратно на обучающие и тестовые наборы."]},{"cell_type":"code","metadata":{"id":"AwHCQvSe-zEO"},"source":["X_train = data[pd.notnull(data['Survived'])].drop(['Survived'], axis=1)\n","y_train = data[pd.notnull(data['Survived'])]['Survived']\n","X_test = data[pd.isnull(data['Survived'])].drop(['Survived'], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_3rmxIdWEDGx"},"source":["print(f'{X_train.shape}, {y_train.shape}, {X_test.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TGU_vLNOE6Lq"},"source":["def create_model(lyrs=[8], act='linear', opt='adam', dr=0.0):\n","    \n","    model = tf.keras.Sequential()\n","    \n","    # create first hidden layer\n","    model.add(tf.keras.layers.Dense(lyrs[0], input_dim=X_train.shape[1], \n","                                    activation=act))\n","    \n","    # create additional hidden layers\n","    for i in range(1,len(lyrs)):\n","        model.add(tf.keras.layers.Dense(lyrs[i], activation=act))\n","    \n","    # add dropout, default is none\n","    model.add(tf.keras.layers.Dropout(dr))\n","    \n","    # create output layer\n","    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # output layer\n","    \n","    model.compile(optimizer=opt,\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZawTIz6OFANl"},"source":["model = create_model()\n","print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7FOUMNhGpqo"},"source":["history = model.fit(X_train,\n","                    y_train, \n","                    epochs=100, \n","                    batch_size=32,\n","                    validation_split=0.2,\n","                    verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0EU9ZjTlHa4w"},"source":["history_dict = history.history\n","history_dict.keys()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v7jjsZ5WICDN"},"source":["## Оценка результатов"]},{"cell_type":"code","metadata":{"id":"HSemPsW1Ql0w"},"source":["def print_summarize_history(history):\n","  # summarize history for accuracy\n","  plt.plot(history.history['acc'])\n","  plt.plot(history.history['val_acc'])\n","  plt.title('model accuracy')\n","  plt.ylabel('accuracy')\n","  plt.xlabel('epoch')\n","  plt.legend(['train', 'validation'], loc='upper left')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKrrAFwnH6ct"},"source":["print_summarize_history(history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Поиск по сетке"],"metadata":{"id":"1DTpLoe-qiAT"}},{"cell_type":"markdown","source":["## Вычисление оптимального размера батча и эпохи"],"metadata":{"id":"adgRzbbyqjaT"}},{"cell_type":"markdown","metadata":{"id":"25tQXsHSIRh5"},"source":["\n","\n","Из приведенного выше графика видно, что мы, возможно, слишком долго тренируем нашу сеть. Давайте воспользуемся поиском по сетке, чтобы узнать, каковы оптимальные значения для `batch_size` и `epochs`. Для этого воспользуемся оболочкой [Scikit-Learn API](https://keras.io/scikit-learn-api/) `KerasClassifier`. Поиск по сетке с перекрестной проверкой ([`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV)) - это грубая сила при поиске лучших гиперпараметров для конкретного набора данных и модели. \n"]},{"cell_type":"code","metadata":{"id":"T8S8ZdmLJSe5"},"source":["model = KerasClassifier(build_fn=create_model, verbose=0)\n","\n","# define the grid search parameters\n","batch_size = [16, 32, 64]\n","epochs = [50, 100]\n","param_grid = dict(batch_size=batch_size, epochs=epochs)\n","\n","# search the grid\n","grid = GridSearchCV(estimator=model, \n","                    param_grid=param_grid,\n","                    cv=3,\n","                    verbose=2)  # include n_jobs=-1 if you are using CPU\n","\n","grid_result = grid.fit(X_train, y_train)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZB7xkeZdK6TC"},"source":["Сделаем какие-то выводы:"]},{"cell_type":"code","metadata":{"id":"wAUlhveIK88-"},"source":["def make_some_conclusion(grid_result):\n","  # summarize results\n","  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","  means = grid_result.cv_results_['mean_test_score']\n","  stds = grid_result.cv_results_['std_test_score']\n","  params = grid_result.cv_results_['params']\n","  for mean, stdev, param in zip(means, stds, params):\n","      print(\"%f (%f) with: %r\" % (mean, stdev, param))\n","\n","make_some_conclusion(grid_result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SsByiNqoLDq0"},"source":["## Поиск алгоритма оптимизации"]},{"cell_type":"code","metadata":{"id":"YQBN0vG-LNAO"},"source":["# create model\n","model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n","\n","# define the grid search parameters\n","optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Nadam']\n","param_grid = dict(opt=optimizer)\n","\n","# search the grid\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=2)\n","grid_result = grid.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ff_fmO_NLQYs"},"source":["Сделаем какие-то выводы:"]},{"cell_type":"code","metadata":{"id":"2_hGK-D9LSjq"},"source":["make_some_conclusion(grid_result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xLcja3e5L3tz"},"source":["## Поиск оптимального количества скрытых слоев"]},{"cell_type":"code","metadata":{"id":"GqyiwFQmL2-d"},"source":["# create model\n","\n","model = KerasClassifier(build_fn=create_model, \n","                        epochs=50, batch_size=32, verbose=0)\n","\n","# define the grid search parameters\n","layers = [(8),(10),(10,5),(12,6),(12,8,4)]\n","param_grid = dict(lyrs=layers)\n","\n","# search the grid\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=2)\n","grid_result = grid.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"arfQ7RBWMDsW"},"source":["Снова сделаем какие-то выводы:"]},{"cell_type":"code","metadata":{"id":"QaQ9zzgaMEwV"},"source":["make_some_conclusion(grid_result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G0CeM8NBOrZ6"},"source":["## Dropout"]},{"cell_type":"code","metadata":{"id":"x5Z0D7-ROtOw"},"source":["# create model\n","model = KerasClassifier(build_fn=create_model, \n","                        epochs=50, batch_size=32, verbose=0)\n","\n","# define the grid search parameters\n","drops = [0.0, 0.01, 0.05, 0.1, 0.2, 0.5]\n","param_grid = dict(dr=drops)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=2)\n","grid_result = grid.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-TpcY6R9POrD"},"source":["Снова сделаем какие-то выводы:"]},{"cell_type":"code","metadata":{"id":"vOIBj2WVPNsz"},"source":["make_some_conclusion(grid_result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lpj-lE6PPW2t"},"source":["## Дорабатываем модель"]},{"cell_type":"code","metadata":{"id":"H7kAHMgaPkIG"},"source":["model = create_model(opt='Nadam', lyrs=[12, 6], dr=0.0)\n","\n","print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GqQScRIPWG3"},"source":["# train model on full train set, with 80/20 CV split\n","training = model.fit(X_train, y_train, epochs=50, batch_size=16, \n","                     validation_split=0.2, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sFkvQXvCQNEG"},"source":["print_summarize_history(training)"],"execution_count":null,"outputs":[]}]}